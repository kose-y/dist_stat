import torch
from .pet_utils import *
from . import distmat
import torch.distributed as dist
class PET_L1():
    def __init__(self, y, emat, D, sig, tau, rho=1e-2, TType=torch.DoubleTensor, eps=1e-20):
        """
        y: count data, d x 1
        emat: "E" matrix generated by E_generate, d x p dense (or sparse)
        d: difference matrix (sparse) to define loss, (#edges) x p sparse
        mu: smoothness parameter
        """
        if emat.chunk.layout == torch.strided:
            assert not emat.byrow
        self.TType=TType

        emat_typename = torch.typename(emat.chunk).split('.')[-1]
        self.d = emat.shape[0]
        self.p = emat.shape[1]
        if emat.chunk.is_cuda:
            SpTType = getattr(torch.cuda.sparse, emat_typename)
        else:
            SpTType = getattr(torch.sparse, emat_typename)
        self.y = y.type(TType).view(-1, 1)
        if emat.chunk.layout == torch.sparse_coo:
            self.E = emat.type(SpTType)
            self.Et = self.E.t().coalesce()
            self.E = self.E.coalesce()
        else: 
            self.E = emat.type(TType)
            self.Et = self.E.t()

        #self.G= G.type(SpTType)
        self.D = D.type(SpTType)
        self.Dt = self.D.t().coalesce()
        self.D = self.D.coalesce()

        self.z = - torch.ones(self.E.shape[0], 1).type(TType) # not dist
        self.w = torch.zeros(self.D.shape[0], 1).type(TType) # not dist
        self.lambd = distmat.distgen_ones(self.E.shape[1], 1).type(TType)
        self.lambd_prev = distmat.distgen_ones(self.E.shape[1], 1).type(TType)
        
        self.Et1     = - distmat.mm(self.Et, self.z) # z init as -1
        
        self.prev_obj=inf
        
        self.tau = tau
        self.sig = sig
        self.rho = rho
        self.eps = eps
        

    def update(self):
        tau = self.tau; sig = self.sig
        Etz = distmat.mm(self.Et, self.z)
        Dtw = distmat.mm(self.Dt, self.w)

        self.lambd = self.lambd - tau * (Etz + Dtw + self.Et1)
        self.lambd = self.lambd.apply(torch.clamp, min=0.0)

        lambd_tilde = 2*self.lambd - self.lambd_prev
        el = distmat.mm(self.E, lambd_tilde) 
        self.z = self.z + sig * el
        tmp = (self.z**2 + 4*sig * self.y).sqrt()
        self.z = 0.5 * (self.z - tmp)
        dl = distmat.mm(self.D, lambd_tilde)
        self.w = self.w + sig * dl
        self.w = torch.clamp(self.w, max=self.rho, min=-self.rho)

    def get_objective(self):
        el = distmat.mm(self.E, self.lambd)
        likelihood = (self.y * torch.log(el+self.eps) - el).sum()
        dl = distmat.mm(self.D, self.lambd)
        penalty = - self.rho * torch.sum(dl.abs())
        return  likelihood + penalty

    def check_convergence(self, tol, verbose=True, check_obj=False, check_interval=1):
        obj = None
        diff_norm = ((self.lambd_prev - self.lambd).abs()).max()
        if check_obj:
            obj = self.get_objective()
            reldiff = abs(self.prev_obj - obj)/((abs(obj)+1)*check_interval)
            converged = reldiff < tol
            self.prev_obj = obj
        else:
            reldiff = None
            converged = diff_norm < tol
        return (diff_norm, reldiff, obj), converged
    def run(self, maxiter=1000, tol=1e-5, check_interval=1, verbose=True, check_obj=False):
        rank = dist.get_rank()
        if verbose:
            if rank==0:
                print("Starting...")
                print("d={}, p={}".format(self.d, self.p))
                if not check_obj:
                    print("%6s\t%13s\t%15s" % ("iter", "maxdiff", "time"))
                else:
                    print("%6s\t%13s\t%15s\t%15s\t%10s" % ("iter", "maxdiff", "reldiff", "obj", "time" ))
                print('-'*80)
        t0 = time.time()
        t_start = t0

        for i in range(maxiter):
            dist.barrier()
            self.lambd_prev.copy_(self.lambd)
            self.update()
            if (i+1) % check_interval ==0:
                t1 = time.time()
                (maxdiff, reldiff, obj), converged = self.check_convergence(tol, verbose, check_obj, 
                                                                            check_interval)
                if verbose:
                    if not check_obj:
                        if rank==0:
                            print("%6d\t%13.4e\t%10.5f" % (i+1, maxdiff, t1-t0))
                    else:
                        if rank==0:
                            print("%6d\t%13.4e\t%15.9e\t%15.9e\t%10.5f" % (i+1, maxdiff, reldiff,
                                                                            obj, t1-t0))
                if converged: break
                t0 = t1
            dist.barrier()

        if verbose:
            if rank==0:
                print('-'*80)
                print("Completed. total time: {}".format(time.time()-t_start))
