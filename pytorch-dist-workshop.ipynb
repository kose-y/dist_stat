{"cells":[{"metadata":{},"cell_type":"markdown","source":"# A Distributed Matrix Data Structure and Its Statistical Applications on PyTorch"},{"metadata":{},"cell_type":"markdown","source":"**NOTE: This notebook is incomplete. At this time, it is uploaded for testing purposes, in preparation of tutorials to be presented in the programming workshop at the inaugural Lange's Symposium on Feb 21-22, 2020.**"},{"metadata":{},"cell_type":"markdown","source":"## Synopsis"},{"metadata":{},"cell_type":"markdown","source":"We developed a distributed matrix operation package suitable for distributed matrix-vector operations and distributed tall-and-thin (or wide-and-short) matrices.\nThe code runs on both multi-node machines and multi-GPU machines using PyTorch.\nWe apply this package for four statistical applications, namely, nonnegative matrix factorization (NMF), multidimensional scaling (MDS), positron emission tomography (PET), and $\\ell_1$-regularized Cox regression.\nIn particular, $\\ell_1$-regularized Cox regression with the UK Biobank dataset was the biggest multivariate survival analysis to our knowledge. \nIn this workshop, we provide small examples that run on a single node, and demonstrate multi-GPU usage on our own machine."},{"metadata":{},"cell_type":"markdown","source":"## Introduction to PyTorch"},{"metadata":{},"cell_type":"markdown","source":"What is PyTorch?"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Basic PyTorch Operations"},{"metadata":{},"cell_type":"markdown","source":"We introduce simple operations on PyTorch. Note that Python uses 0-based, rowmajor ordering, like C and C++ (R is 1-based, column-major ordering). First we import the PyTorch\nlibrary. This is equvalent to library() in R."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.__version__","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"'1.1.0'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tensor Creation"},{"metadata":{},"cell_type":"markdown","source":"One may create an uninitialized tensor. This creates a 3 Ã— 4 tensor (matrix)."},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.empty(3, 4) # uninitialized tensor","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"tensor([[5.9179e+09, 4.5741e-41, 5.9179e+09, 4.5741e-41],\n        [1.9421e+31, 2.7491e+20, 6.1949e-04, 1.2140e+33],\n        [3.2307e-18, 7.1760e+22, 7.2250e+28, 2.5226e-18]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The following is equivalent to `set.seed()` in R."},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(100)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"<torch._C.Generator at 0x7f81c2c5a310>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"This generates a tensor initialized with random values from (0, 1)."},{"metadata":{"trusted":true},"cell_type":"code","source":"y = torch.rand(3, 4) # from Unif(0, 1)\ny","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"tensor([[0.1117, 0.8158, 0.2626, 0.4839],\n        [0.6765, 0.7539, 0.2627, 0.0428],\n        [0.2080, 0.1180, 0.1217, 0.7356]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We can also generate a tensor filled with zeros or ones."},{"metadata":{"trusted":true},"cell_type":"code","source":"z = torch.ones(3, 4) # torch.zeros(3, 4)\nz","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"tensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"A tensor can be created from standard Python data."},{"metadata":{"trusted":true},"cell_type":"code","source":"w = torch.tensor([3, 4, 5, 6])\nw","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"tensor([3, 4, 5, 6])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"A tensor can be created in certain datatype (default: float32) and on certain device (default: CPU) of choice "},{"metadata":{"trusted":true},"cell_type":"code","source":"# double precision\nw = torch.tensor([3, 4, 5, 6], dtype=torch.float64)\nw","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"tensor([3., 4., 5., 6.], dtype=torch.float64)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# on GPU number zero. will not run if CUDA GPU is not present.\nw = torch.tensor([3, 4, 5, 6], device='cuda:0')\nw","execution_count":9,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-889566a53370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# on GPU number zero. will not run if CUDA GPU is not present.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m         raise RuntimeError(\n\u001b[1;32m    161\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"]}]},{"metadata":{},"cell_type":"markdown","source":"Shape of a tensor can be accessed by appending `.shape` to the tensor name."},{"metadata":{"trusted":true},"cell_type":"code","source":"z.shape","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"torch.Size([3, 4])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Casting"},{"metadata":{},"cell_type":"markdown","source":"A tensor can change datatype and location by the method `.to()`. The arguments are similar to choosing datatype and device of the new tensor."},{"metadata":{"trusted":true},"cell_type":"code","source":"w = w.to(device = \"cpu\", dtype=torch.int32)\nw","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"tensor([3, 4, 5, 6], dtype=torch.int32)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Indexing"},{"metadata":{},"cell_type":"markdown","source":"The following are standard method of indexing tensors."},{"metadata":{"trusted":true},"cell_type":"code","source":"y[2, 3] # indexing: zero-based, returns a 0-dimensional tensor","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"tensor(0.7356)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The indexing always returns a (sub)tensor, even for scalars (treated as zero-dimensional tensors).\nA standard Python number can be returned by using .item()."},{"metadata":{"trusted":true},"cell_type":"code","source":"y[2, 3].item() # A standard Python floating-point number","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0.7355988621711731"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"To get a column from a tensor, we use the indexing as below. The syntax is similar but slightly\ndifferent from R."},{"metadata":{"trusted":true},"cell_type":"code","source":"y[:, 3] # 3rd column. The leftmost column is 0th. cf. y[, 4] in R","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"tensor([0.4839, 0.0428, 0.7356])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The following is for taking a row."},{"metadata":{"trusted":true},"cell_type":"code","source":"y[2, :] # 2nd row. The top row is 0th. cf. y[3, ] in R","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"tensor([0.2080, 0.1180, 0.1217, 0.7356])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Simple operations"},{"metadata":{},"cell_type":"markdown","source":"Here we provide an example of simple operations on PyTorch. Addition using the operator â€˜+â€™ acts\njust like anyone can expect:"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = y + z # a simple addition.\nx","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"tensor([[1.1117, 1.8158, 1.2626, 1.4839],\n        [1.6765, 1.7539, 1.2627, 1.0428],\n        [1.2080, 1.1180, 1.1217, 1.7356]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Here is another form of addition."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = torch.add(y, z) # another syntax for addition","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The operators ending with an underscore (`_`) changes the value of the tensor in-place. Otherwise, the argument never changes. Unlike methods ending with `!` in Julia, this rule is strictly enforced in PyTorch. (The underscore determines usage of the keyword `const` in C++-level.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.add_(z) # in-place addition","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"tensor([[1.1117, 1.8158, 1.2626, 1.4839],\n        [1.6765, 1.7539, 1.2627, 1.0428],\n        [1.2080, 1.1180, 1.1217, 1.7356]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Concatenation"},{"metadata":{},"cell_type":"markdown","source":"We can concatenate the tensors using the function `cat()`, which resembles `c()`, `cbind()`, and\n`rbind()` in R. The second argument indicates the dimension that the tesors are concatenated\nalong: zero means by concatenation by rows, and one means by columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cat((y, z), 0) # along the rows","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"tensor([[1.1117, 1.8158, 1.2626, 1.4839],\n        [1.6765, 1.7539, 1.2627, 1.0428],\n        [1.2080, 1.1180, 1.1217, 1.7356],\n        [1.0000, 1.0000, 1.0000, 1.0000],\n        [1.0000, 1.0000, 1.0000, 1.0000],\n        [1.0000, 1.0000, 1.0000, 1.0000]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cat((y, z), 1) # along the columns","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"tensor([[1.1117, 1.8158, 1.2626, 1.4839, 1.0000, 1.0000, 1.0000, 1.0000],\n        [1.6765, 1.7539, 1.2627, 1.0428, 1.0000, 1.0000, 1.0000, 1.0000],\n        [1.2080, 1.1180, 1.1217, 1.7356, 1.0000, 1.0000, 1.0000, 1.0000]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Reshaping"},{"metadata":{},"cell_type":"markdown","source":"One can reshape a tensor, like changing the attribute `dim` in R."},{"metadata":{"trusted":true},"cell_type":"code","source":"y.view(12) # 1-dimensional array","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"tensor([1.1117, 1.8158, 1.2626, 1.4839, 1.6765, 1.7539, 1.2627, 1.0428, 1.2080,\n        1.1180, 1.1217, 1.7356])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Up to one of the arguments of `view()` can be âˆ’1. The size of the reshaped tensor is inferred\nfrom the other dimensions."},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape into (6)-by-2 tensor;\n# (6) is inferred from the other dimension\ny.view(-1, 2)","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"tensor([[1.1117, 1.8158],\n        [1.2626, 1.4839],\n        [1.6765, 1.7539],\n        [1.2627, 1.0428],\n        [1.2080, 1.1180],\n        [1.1217, 1.7356]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Basic statistics"},{"metadata":{},"cell_type":"markdown","source":"Calling `.sum()`, `.mean()`, `.std()` methods of a tensor do the obvious. Optional argument determines the dimension of reduction."},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"tensor([[1.1117, 1.8158, 1.2626, 1.4839],\n        [1.6765, 1.7539, 1.2627, 1.0428],\n        [1.2080, 1.1180, 1.1217, 1.7356]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sum()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"tensor(16.5933)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sum(0) # reduces rows, columnwise sum","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"tensor([3.9962, 4.6878, 3.6469, 4.2623])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sum(1) # reduces columns, rowwise sum","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"tensor([5.6739, 5.7359, 5.1834])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sum((0, 1)) # reduces rows and columns -> a single number.","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"tensor(16.5933)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.mean()","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"tensor(1.3828)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.mean(0)","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"tensor([1.3321, 1.5626, 1.2156, 1.4208])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.std(1)","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"tensor([0.3058, 0.3384, 0.2961])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Linear Algebra"},{"metadata":{},"cell_type":"markdown","source":"Matrix transpose is performed by appending `.t()` to a tensor. Matrix multiplication is carried out by the method `torch.mm()`."},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.mm(y, z.t())","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"tensor([[5.6739, 5.6739, 5.6739],\n        [5.7359, 5.7359, 5.7359],\n        [5.1834, 5.1834, 5.1834]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## `torch.distributed`: Distributed subpackage for PyTorch"},{"metadata":{},"cell_type":"markdown","source":"`torch.distributed` is the subpackage for distributed operations on PyTorch. The interface is mostly inspired by the message passing interface (MPI). The available backends are:\n\n* Gloo, a collective communication library developed by Facebook, included in PyTorch. Full support for CPU, partial collective communication only for GPU.\n* MPI, a good-old communication standard. The most flexible, but PyTorch needs to be compiled from its source to use it as a backend. Full support for GPU if the MPI installation is \"CUDA-aware\".\n* NCCL, Nvidia Collective Communications Library, collective communication only for multiple GPUs on the same machine."},{"metadata":{},"cell_type":"markdown","source":"For this workshop, we use Gloo for its full functionalities on CPU and runnability on Jupyter Notebook. The experiments in our paper use MPI for running multi-node setting and multi-GPU setting with basically the same code. The interface below is specific for Gloo backend. For MPI backend, please consult with a section from [distributed package tutorial](https://pytorch.org/tutorials/intermediate/dist_tuto.html#communication-backends) or [our code](https://github.com/kose-y/dist_stat/tree/master/examples)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nimport torch.distributed as dist\nfrom torch.multiprocessing import Process\n\ndef init_process(rank, size, fn, backend='gloo'):\n    \"\"\" Initialize the distributed environment. \"\"\"\n    os.environ['MASTER_ADDR'] = '127.0.0.1'\n    os.environ['MASTER_PORT'] = '29500'\n    dist.init_process_group(backend, rank=rank, world_size=size)\n    fn(rank, size)\n\ndef run_process(size, fn):\n    processes = []\n    for rank in range(size):\n        p = Process(target=init_process, args=(rank, size, fn))\n        p.start()\n        processes.append(p)\n        \n    for p in processes:\n        p.join()","execution_count":32,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Point-to-point communication"},{"metadata":{},"cell_type":"markdown","source":"![](https://pytorch.org/tutorials/_images/send_recv.png)\nFigure courtesy of: https://pytorch.org/tutorials/_images/send_recv.png"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Blocking point-to-point communication.\"\"\"\n\ndef point_to_point(rank, size):\n    tensor = torch.zeros(1)\n    if rank == 0:\n        tensor += 1\n        # Send the tensor to process 1\n        dist.send(tensor=tensor, dst=1)\n    elif rank == 1:\n        # Receive tensor from process 0\n        dist.recv(tensor=tensor, src=0)\n    dist.barrier()\n    print('Rank ', rank, ' has data ', tensor[0])","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, point_to_point)","execution_count":34,"outputs":[{"output_type":"stream","text":"Rank  1  has data  tensor(1.)\nRank  3  has data  tensor(0.)\nRank  2  has data  tensor(0.)\nRank  0  has data  tensor(1.)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Collective communication"},{"metadata":{},"cell_type":"markdown","source":"| | | \n|:---|:---|\n| ![](https://pytorch.org/tutorials/_images/scatter.png) | ![](https://pytorch.org/tutorials/_images/gather.png) |\n| Scatter | Gather |\n| ![](https://pytorch.org/tutorials/_images/reduce.png) | ![](https://pytorch.org/tutorials/_images/all_reduce.png) |\n| Reduce | All-reduce |\n| ![](https://pytorch.org/tutorials/_images/broadcast.png) | ![](https://pytorch.org/tutorials/_images/all_gather.png) |\n| Broadcast | All-gather |\n\nTable courtesy of: https://pytorch.org/tutorials/intermediate/dist_tuto.html#communication-backends\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def broadcast(rank, size):\n    tensor = torch.zeros(1)\n    if rank == 0:\n        tensor[0] = 7\n    dist.broadcast(tensor, src=0)\n    print('Rank ', rank, ' has data ', tensor[0])","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, broadcast)","execution_count":36,"outputs":[{"output_type":"stream","text":"Rank  2  has data  tensor(7.)\nRank  3  has data  tensor(7.)\nRank  1  has data  tensor(7.)\nRank  0  has data  tensor(7.)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce(rank, size):\n    tensor = torch.ones(1)\n    dist.reduce(tensor, 3)\n    print('Rank ', rank, ' has data ', tensor[0])","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, reduce)","execution_count":38,"outputs":[{"output_type":"stream","text":"Rank  2  has data  tensor(2.)\nRank  3  has data  tensor(4.)\nRank  1  has data  tensor(3.)\nRank  0  has data  tensor(4.)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def all_reduce(rank, size):\n    tensor = torch.ones(1)\n    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n    print('Rank ', rank, ' has data ', tensor[0])","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, all_reduce)","execution_count":40,"outputs":[{"output_type":"stream","text":"Rank  3  has data  tensor(4.)\nRank  1  has data  tensor(4.)\nRank  2  has data  tensor(4.)\nRank  0  has data  tensor(4.)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def all_gather(rank, size):\n    tensors = [torch.zeros(1) for i in range(size)]\n    dat = torch.zeros(1)\n    dat[0] += rank\n    dist.all_gather(tensors, dat)\n    print('Rank ', rank, ' has data ', tensors)","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, all_gather)","execution_count":42,"outputs":[{"output_type":"stream","text":"Rank  1  has data  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]\nRank  2  has data  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]\nRank  3  has data  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]\nRank  0  has data  [tensor([0.]), tensor([1.]), tensor([2.]), tensor([3.])]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## `distmat`: Distributed Matrices on PyTorch"},{"metadata":{},"cell_type":"markdown","source":"Using the tensor operations and communication package, we created a data structure for a distributed matrix. In this structure, each process,\nenumerated by its rank, holds a contiguous block of the full data matrix by rows or columns.\nThe data may be a sparse matrix. If GPUs are involved, each process controls a GPU whose\nindex matches the process rank. For notational simplicity, we denote the dimension to split\nin square brackets. If a [100] Ã— 100 matrix is split over four processes, the process with rank\n0 keeps the first 25 rows of the matrix, and the rank 3 process takes the last 25 rows. For\nthe sake of simplicity, we always assume that the size along the split dimension is divided\nby the number of processes."},{"metadata":{"trusted":true},"cell_type":"code","source":"import dist_stat.distmat as distmat","execution_count":43,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creation"},{"metadata":{},"cell_type":"markdown","source":"- `distgen_ones()`: Creates a distributed matrix filled with ones\n- `distgen_zeros()`: Creates a distributed matrix filled with zeros\n- `distgen_uniform()`: Creates a distributed matrix from uniform distribution\n- `distgen_normal()`: Creates a distributed matrix from stndard normal distribution "},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_unif(rank, size):\n    A = distmat.distgen_uniform(8, 8, TType=torch.DoubleTensor)\n    print('Matrix A:', 'Rank ', rank, ' has data ', A.chunk)   ","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, create_unif)","execution_count":72,"outputs":[{"output_type":"stream","text":"Matrix A: Rank  1  has data  tensor([[0.5459, 0.3573, 0.2406, 0.5600, 0.6501, 0.9692, 0.5168, 0.2422],\n        [0.4312, 0.5917, 0.3425, 0.2202, 0.7030, 0.5629, 0.9259, 0.7612]],\n       dtype=torch.float64)\nMatrix A: Rank  3  has data  tensor([[0.6214, 0.7096, 0.7099, 0.7977, 0.8779, 0.1236, 0.5650, 0.0655],\n        [0.1210, 0.0454, 0.5070, 0.1860, 0.5035, 0.1454, 0.8090, 0.4991]],\n       dtype=torch.float64)\nMatrix A: Rank  2  has data  tensor([[0.8381, 0.4943, 0.5984, 0.6167, 0.6128, 0.8593, 0.1344, 0.5146],\n        [0.1479, 0.4238, 0.5144, 0.7051, 0.8133, 0.1795, 0.2721, 0.4631]],\n       dtype=torch.float64)\nMatrix A: Rank  0  has data  tensor([[0.6941, 0.3464, 0.9751, 0.7911, 0.4274, 0.4460, 0.5522, 0.9559],\n        [0.9405, 0.2215, 0.3271, 0.1352, 0.6283, 0.3030, 0.1302, 0.1811]],\n       dtype=torch.float64)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def from_chunks(rank, size):\n    torch.manual_seed(100 + rank)\n    chunk = torch.randn(2, 4)\n    print(\"rank \", rank, \"has chunk\", chunk)\n    A = distmat.THDistMat.from_chunks(chunk)\n    print('Matrix A:', 'Rank ', rank, ' has data ', A.chunk)       ","execution_count":81,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, from_chunks)","execution_count":82,"outputs":[{"output_type":"stream","text":"rank  2 has chunk tensor([[ 0.9907,  0.3349,  1.1497, -0.5498],\n        [-0.1046,  2.0104, -0.7886, -0.1246]])rank  1 has chunk tensor([[-1.3905, -0.8152, -0.3204,  0.7377],\n        [-1.7534,  0.6033, -0.2520, -0.4373]])rank  0 has chunk tensor([[ 0.3607, -0.2859, -0.3938,  0.2429],\n        [-1.3833, -2.3134, -0.3172, -0.8660]])\nrank  3 has chunk tensor([[ 1.7286, -0.4007,  2.5587,  1.6848],\n        [-1.6571, -0.2811,  0.7743, -0.9554]])\n\n\nMatrix A: Rank  1  has data  tensor([[-1.3905, -0.8152, -0.3204,  0.7377],\n        [-1.7534,  0.6033, -0.2520, -0.4373]])Matrix A: Rank  3  has data  tensor([[ 1.7286, -0.4007,  2.5587,  1.6848],\n        [-1.6571, -0.2811,  0.7743, -0.9554]])\nMatrix A: Rank  2  has data  tensor([[ 0.9907,  0.3349,  1.1497, -0.5498],\n        [-0.1046,  2.0104, -0.7886, -0.1246]])\nMatrix A: Rank  0  has data  tensor([[ 0.3607, -0.2859, -0.3938,  0.2429],\n        [-1.3833, -2.3134, -0.3172, -0.8660]])\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Elementwise operations"},{"metadata":{},"cell_type":"markdown","source":"Some of the basic functions work naturally. "},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"C = A + B","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"A.log()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For general functions, we have `.apply()`, `.apply_binary()`, `.apply_inplace()`, and `.apply_inplace_binary()`."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reductions (sum, product, max, min)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_distmat(rank, size):\n    \n    if rank==0:\n        p = 12; q = 12\n        data = torch.DoubleTensor(p,q).normal_()\n        print(data)\n    else:\n        data = None\n\n    rslt = distmat.dist_data(data, src=0, TType=torch.DoubleTensor)\n\n    print(rank, rslt.chunk)\n\n    r1 = rslt.diag()\n\n    print(r1.chunk)\n\n    r2 = rslt.diag(distribute=False)\n    print(r2)\n\n    rr = rslt + rslt\n\n    print(rank, rslt.chunk, rr.chunk)\n\n    dist.barrier()\n\n    rslt += rslt\n    print(\"rslt += rslt\", rank, rslt.chunk)\n\n    print((1 + rslt).chunk)\n    print((rslt + torch.arange(12, out=torch.DoubleTensor(1,12))).chunk)\n    # print((torch.arange(12, out=TType(1,12)) + rslt).chunk) # doesn't work\n\n    if rank==0:\n        col0 = data[:, 0].view(-1, 1)\n    else:\n        col0 = None\n    if rank==0:\n        print(col0)\n    col0_dist = distmat.dist_data(col0, src=0, TType=torch.DoubleTensor)\n    print(\"adding by 1st col of data\", rank, (rslt + col0_dist).chunk)\n    rslt.fill_diag_(0)\n    print(\"rslt, diagonal set to zero\", rank, rslt.chunk)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, test_distmat)","execution_count":71,"outputs":[{"output_type":"stream","text":"tensor([[ 1.4328e+00,  1.6422e-01, -1.2654e+00,  1.1688e+00, -7.3106e-01,\n         -3.5541e-01,  8.6673e-01,  1.0486e+00, -5.6238e-01,  9.0757e-01,\n          2.4049e+00,  1.3290e+00],\n        [-7.6193e-01,  1.0270e+00,  9.2496e-01,  2.2676e+00, -1.1411e+00,\n         -7.8844e-01, -4.0719e-01,  2.3872e-01, -4.2209e-01, -2.4347e+00,\n          1.0778e+00,  5.2347e-02],\n        [ 5.2616e-01, -5.1227e-01,  6.2022e-01,  1.2590e+00, -1.3863e+00,\n         -1.0154e+00, -5.4141e-01, -7.4287e-01,  1.1423e+00, -1.0365e+00,\n         -1.3453e+00, -3.8520e-01],\n        [ 5.3353e-01,  8.4845e-01, -7.4295e-02, -1.1702e+00,  1.5286e+00,\n          5.3773e-01, -1.2187e-01, -1.3303e+00, -1.2701e+00,  1.7897e+00,\n          5.3221e-01,  2.7608e-01],\n        [ 1.0102e+00,  1.5088e+00, -1.5716e+00,  6.9977e-01, -2.0505e+00,\n          3.1391e-01,  4.6768e-01, -3.6801e-01,  9.6022e-01,  4.4294e-01,\n         -6.9029e-02,  1.6452e+00],\n        [-4.5622e-02,  4.0654e-01, -1.2026e+00,  2.0411e-03, -1.8043e+00,\n          8.2580e-02,  5.0374e-01,  6.9411e-01, -2.2087e+00,  1.3463e+00,\n          1.5256e+00, -1.5273e-01],\n        [-3.4272e-01,  2.1705e+00, -1.1574e+00,  1.1983e+00,  1.2851e+00,\n         -5.3635e-01,  3.2686e-01,  4.5538e-01,  1.0076e+00, -2.1746e+00,\n         -1.1285e-01,  1.1754e+00],\n        [ 1.0031e+00,  7.5883e-01,  1.9497e+00, -6.0872e-01, -7.9935e-01,\n         -1.2683e-01, -5.7979e-01, -1.8324e-01, -1.3248e+00, -1.7352e+00,\n         -8.2467e-01, -5.5403e-01],\n        [-2.4177e+00,  5.2934e-01, -1.1067e+00,  8.0449e-01,  1.2752e+00,\n         -1.6422e+00,  1.4741e+00, -2.4966e-01,  4.7979e-01,  1.8154e+00,\n          2.2954e+00, -8.5566e-01],\n        [ 7.4129e-01,  2.0976e+00,  1.3937e+00, -9.6171e-01,  7.0328e-01,\n         -1.3079e+00, -8.2445e-02, -2.1201e-01,  1.5871e-01, -8.6191e-02,\n          5.1527e-02, -1.6462e+00],\n        [ 5.0368e-01, -9.8740e-01,  1.6135e+00, -1.1814e+00,  5.6406e-01,\n          2.0001e+00,  9.2043e-01,  1.9047e+00,  1.5785e+00, -1.5525e+00,\n          5.8823e-01, -4.4320e-01],\n        [ 8.9618e-01, -1.3487e+00, -6.0016e-01, -1.1699e-01,  1.5793e+00,\n         -1.3010e+00,  1.3046e+00,  8.1265e-01, -2.1337e+00,  1.6958e+00,\n          7.6979e-01,  1.9723e+00]], dtype=torch.float64)\n0 tensor([[ 1.4328,  0.1642, -1.2654,  1.1688, -0.7311, -0.3554,  0.8667,  1.0486,\n         -0.5624,  0.9076,  2.4049,  1.3290],\n        [-0.7619,  1.0270,  0.9250,  2.2676, -1.1411, -0.7884, -0.4072,  0.2387,\n         -0.4221, -2.4347,  1.0778,  0.0523],\n        [ 0.5262, -0.5123,  0.6202,  1.2590, -1.3863, -1.0154, -0.5414, -0.7429,\n          1.1423, -1.0365, -1.3453, -0.3852]], dtype=torch.float64)2 tensor([[-0.3427,  2.1705, -1.1574,  1.1983,  1.2851, -0.5364,  0.3269,  0.4554,\n          1.0076, -2.1746, -0.1128,  1.1754],\n        [ 1.0031,  0.7588,  1.9497, -0.6087, -0.7994, -0.1268, -0.5798, -0.1832,\n         -1.3248, -1.7352, -0.8247, -0.5540],\n        [-2.4177,  0.5293, -1.1067,  0.8045,  1.2752, -1.6422,  1.4741, -0.2497,\n          0.4798,  1.8154,  2.2954, -0.8557]], dtype=torch.float64)1 tensor([[ 5.3353e-01,  8.4845e-01, -7.4295e-02, -1.1702e+00,  1.5286e+00,\n          5.3773e-01, -1.2187e-01, -1.3303e+00, -1.2701e+00,  1.7897e+00,\n          5.3221e-01,  2.7608e-01],\n        [ 1.0102e+00,  1.5088e+00, -1.5716e+00,  6.9977e-01, -2.0505e+00,\n          3.1391e-01,  4.6768e-01, -3.6801e-01,  9.6022e-01,  4.4294e-01,\n         -6.9029e-02,  1.6452e+00],\n        [-4.5622e-02,  4.0654e-01, -1.2026e+00,  2.0411e-03, -1.8043e+00,\n          8.2580e-02,  5.0374e-01,  6.9411e-01, -2.2087e+00,  1.3463e+00,\n          1.5256e+00, -1.5273e-01]], dtype=torch.float64)\n\n3 tensor([[ 0.7413,  2.0976,  1.3937, -0.9617,  0.7033, -1.3079, -0.0824, -0.2120,\n          0.1587, -0.0862,  0.0515, -1.6462],\n        [ 0.5037, -0.9874,  1.6135, -1.1814,  0.5641,  2.0001,  0.9204,  1.9047,\n          1.5785, -1.5525,  0.5882, -0.4432],\n        [ 0.8962, -1.3487, -0.6002, -0.1170,  1.5793, -1.3010,  1.3046,  0.8127,\n         -2.1337,  1.6958,  0.7698,  1.9723]], dtype=torch.float64)\n\ntensor([[ 0.3269],\n        [-0.1832],\n        [ 0.4798]], dtype=torch.float64)tensor([[1.4328],\n        [1.0270],\n        [0.6202]], dtype=torch.float64)tensor([[-1.1702],\n        [-2.0505],\n        [ 0.0826]], dtype=torch.float64)tensor([[-0.0862],\n        [ 0.5882],\n        [ 1.9723]], dtype=torch.float64)\n\n\n\ntensor([[ 1.4328],\n        [ 1.0270],\n        [ 0.6202],\n        [-1.1702],\n        [-2.0505],\n        [ 0.0826],\n        [ 0.3269],\n        [-0.1832],\n        [ 0.4798],\n        [-0.0862],\n        [ 0.5882],\n        [ 1.9723]], dtype=torch.float64)tensor([[ 1.4328],\n        [ 1.0270],\n        [ 0.6202],\n        [-1.1702],\n        [-2.0505],\n        [ 0.0826],\n        [ 0.3269],\n        [-0.1832],\n        [ 0.4798],\n        [-0.0862],\n        [ 0.5882],\n        [ 1.9723]], dtype=torch.float64)\n\ntensor([[ 1.4328],\n        [ 1.0270],\n        [ 0.6202],\n        [-1.1702],\n        [-2.0505],\n        [ 0.0826],\n        [ 0.3269],\n        [-0.1832],\n        [ 0.4798],\n        [-0.0862],\n        [ 0.5882],\n        [ 1.9723]], dtype=torch.float64)tensor([[ 1.4328],\n        [ 1.0270],\n        [ 0.6202],\n        [-1.1702],\n        [-2.0505],\n        [ 0.0826],\n        [ 0.3269],\n        [-0.1832],\n        [ 0.4798],\n        [-0.0862],\n        [ 0.5882],\n        [ 1.9723]], dtype=torch.float64)\n\n0 tensor([[ 1.4328,  0.1642, -1.2654,  1.1688, -0.7311, -0.3554,  0.8667,  1.0486,\n         -0.5624,  0.9076,  2.4049,  1.3290],\n        [-0.7619,  1.0270,  0.9250,  2.2676, -1.1411, -0.7884, -0.4072,  0.2387,\n         -0.4221, -2.4347,  1.0778,  0.0523],\n        [ 0.5262, -0.5123,  0.6202,  1.2590, -1.3863, -1.0154, -0.5414, -0.7429,\n          1.1423, -1.0365, -1.3453, -0.3852]], dtype=torch.float64)1 tensor([[ 5.3353e-01,  8.4845e-01, -7.4295e-02, -1.1702e+00,  1.5286e+00,\n          5.3773e-01, -1.2187e-01, -1.3303e+00, -1.2701e+00,  1.7897e+00,\n          5.3221e-01,  2.7608e-01],\n        [ 1.0102e+00,  1.5088e+00, -1.5716e+00,  6.9977e-01, -2.0505e+00,\n          3.1391e-01,  4.6768e-01, -3.6801e-01,  9.6022e-01,  4.4294e-01,\n         -6.9029e-02,  1.6452e+00],\n        [-4.5622e-02,  4.0654e-01, -1.2026e+00,  2.0411e-03, -1.8043e+00,\n          8.2580e-02,  5.0374e-01,  6.9411e-01, -2.2087e+00,  1.3463e+00,\n          1.5256e+00, -1.5273e-01]], dtype=torch.float64) tensor([[ 2.8656,  0.3284, -2.5308,  2.3376, -1.4621, -0.7108,  1.7335,  2.0972,\n         -1.1248,  1.8151,  4.8099,  2.6580],\n        [-1.5239,  2.0540,  1.8499,  4.5352, -2.2822, -1.5769, -0.8144,  0.4774,\n         -0.8442, -4.8694,  2.1556,  0.1047],\n        [ 1.0523, -1.0245,  1.2404,  2.5180, -2.7726, -2.0308, -1.0828, -1.4857,\n          2.2845, -2.0730, -2.6905, -0.7704]], dtype=torch.float64)3 tensor([[ 0.7413,  2.0976,  1.3937, -0.9617,  0.7033, -1.3079, -0.0824, -0.2120,\n          0.1587, -0.0862,  0.0515, -1.6462],\n        [ 0.5037, -0.9874,  1.6135, -1.1814,  0.5641,  2.0001,  0.9204,  1.9047,\n          1.5785, -1.5525,  0.5882, -0.4432],\n        [ 0.8962, -1.3487, -0.6002, -0.1170,  1.5793, -1.3010,  1.3046,  0.8127,\n         -2.1337,  1.6958,  0.7698,  1.9723]], dtype=torch.float64)2 tensor([[-0.3427,  2.1705, -1.1574,  1.1983,  1.2851, -0.5364,  0.3269,  0.4554,\n          1.0076, -2.1746, -0.1128,  1.1754],\n        [ 1.0031,  0.7588,  1.9497, -0.6087, -0.7994, -0.1268, -0.5798, -0.1832,\n         -1.3248, -1.7352, -0.8247, -0.5540],\n        [-2.4177,  0.5293, -1.1067,  0.8045,  1.2752, -1.6422,  1.4741, -0.2497,\n          0.4798,  1.8154,  2.2954, -0.8557]], dtype=torch.float64) tensor([[ 1.4826,  4.1952,  2.7874, -1.9234,  1.4066, -2.6159, -0.1649, -0.4240,\n          0.3174, -0.1724,  0.1031, -3.2923],\n        [ 1.0074, -1.9748,  3.2271, -2.3627,  1.1281,  4.0002,  1.8409,  3.8095,\n          3.1569, -3.1050,  1.1765, -0.8864],\n        [ 1.7924, -2.6973, -1.2003, -0.2340,  3.1585, -2.6020,  2.6093,  1.6253,\n         -4.2674,  3.3917,  1.5396,  3.9447]], dtype=torch.float64)\n tensor([[ 1.0671e+00,  1.6969e+00, -1.4859e-01, -2.3405e+00,  3.0573e+00,\n          1.0755e+00, -2.4375e-01, -2.6605e+00, -2.5401e+00,  3.5793e+00,\n          1.0644e+00,  5.5216e-01],\n        [ 2.0204e+00,  3.0176e+00, -3.1433e+00,  1.3995e+00, -4.1010e+00,\n          6.2783e-01,  9.3536e-01, -7.3602e-01,  1.9204e+00,  8.8589e-01,\n         -1.3806e-01,  3.2904e+00],\n        [-9.1244e-02,  8.1309e-01, -2.4052e+00,  4.0822e-03, -3.6087e+00,\n          1.6516e-01,  1.0075e+00,  1.3882e+00, -4.4174e+00,  2.6927e+00,\n","name":"stdout"},{"output_type":"stream","text":"          3.0512e+00, -3.0545e-01]], dtype=torch.float64)\n\n tensor([[-0.6854,  4.3409, -2.3149,  2.3966,  2.5702, -1.0727,  0.6537,  0.9108,\n          2.0153, -4.3491, -0.2257,  2.3507],\n        [ 2.0062,  1.5177,  3.8994, -1.2174, -1.5987, -0.2537, -1.1596, -0.3665,\n         -2.6495, -3.4704, -1.6493, -1.1081],\n        [-4.8354,  1.0587, -2.2134,  1.6090,  2.5504, -3.2844,  2.9482, -0.4993,\n          0.9596,  3.6309,  4.5908, -1.7113]], dtype=torch.float64)\nrslt += rslt 1 tensor([[ 1.0671e+00,  1.6969e+00, -1.4859e-01, -2.3405e+00,  3.0573e+00,\n          1.0755e+00, -2.4375e-01, -2.6605e+00, -2.5401e+00,  3.5793e+00,\n          1.0644e+00,  5.5216e-01],\n        [ 2.0204e+00,  3.0176e+00, -3.1433e+00,  1.3995e+00, -4.1010e+00,\n          6.2783e-01,  9.3536e-01, -7.3602e-01,  1.9204e+00,  8.8589e-01,\n         -1.3806e-01,  3.2904e+00],\n        [-9.1244e-02,  8.1309e-01, -2.4052e+00,  4.0822e-03, -3.6087e+00,\n          1.6516e-01,  1.0075e+00,  1.3882e+00, -4.4174e+00,  2.6927e+00,\n          3.0512e+00, -3.0545e-01]], dtype=torch.float64)rslt += rslt 0 tensor([[ 2.8656,  0.3284, -2.5308,  2.3376, -1.4621, -0.7108,  1.7335,  2.0972,\n         -1.1248,  1.8151,  4.8099,  2.6580],\n        [-1.5239,  2.0540,  1.8499,  4.5352, -2.2822, -1.5769, -0.8144,  0.4774,\n         -0.8442, -4.8694,  2.1556,  0.1047],\n        [ 1.0523, -1.0245,  1.2404,  2.5180, -2.7726, -2.0308, -1.0828, -1.4857,\n          2.2845, -2.0730, -2.6905, -0.7704]], dtype=torch.float64)rslt += rslt 3 tensor([[ 1.4826,  4.1952,  2.7874, -1.9234,  1.4066, -2.6159, -0.1649, -0.4240,\n          0.3174, -0.1724,  0.1031, -3.2923],\n        [ 1.0074, -1.9748,  3.2271, -2.3627,  1.1281,  4.0002,  1.8409,  3.8095,\n          3.1569, -3.1050,  1.1765, -0.8864],\n        [ 1.7924, -2.6973, -1.2003, -0.2340,  3.1585, -2.6020,  2.6093,  1.6253,\n         -4.2674,  3.3917,  1.5396,  3.9447]], dtype=torch.float64)\nrslt += rslt 2 tensor([[-0.6854,  4.3409, -2.3149,  2.3966,  2.5702, -1.0727,  0.6537,  0.9108,\n          2.0153, -4.3491, -0.2257,  2.3507],\n        [ 2.0062,  1.5177,  3.8994, -1.2174, -1.5987, -0.2537, -1.1596, -0.3665,\n         -2.6495, -3.4704, -1.6493, -1.1081],\n        [-4.8354,  1.0587, -2.2134,  1.6090,  2.5504, -3.2844,  2.9482, -0.4993,\n          0.9596,  3.6309,  4.5908, -1.7113]], dtype=torch.float64)\n\n\ntensor([[ 2.0671,  2.6969,  0.8514, -1.3405,  4.0573,  2.0755,  0.7563, -1.6605,\n         -1.5401,  4.5793,  2.0644,  1.5522],\n        [ 3.0204,  4.0176, -2.1433,  2.3995, -3.1010,  1.6278,  1.9354,  0.2640,\n          2.9204,  1.8859,  0.8619,  4.2904],\n        [ 0.9088,  1.8131, -1.4052,  1.0041, -2.6087,  1.1652,  2.0075,  2.3882,\n         -3.4174,  3.6927,  4.0512,  0.6945]], dtype=torch.float64)tensor([[ 0.3146,  5.3409, -1.3149,  3.3966,  3.5702, -0.0727,  1.6537,  1.9108,\n          3.0153, -3.3491,  0.7743,  3.3507],\n        [ 3.0062,  2.5177,  4.8994, -0.2174, -0.5987,  0.7463, -0.1596,  0.6335,\n         -1.6495, -2.4704, -0.6493, -0.1081],\n        [-3.8354,  2.0587, -1.2134,  2.6090,  3.5504, -2.2844,  3.9482,  0.5007,\n          1.9596,  4.6309,  5.5908, -0.7113]], dtype=torch.float64)\ntensor([[ 2.4826,  5.1952,  3.7874, -0.9234,  2.4066, -1.6159,  0.8351,  0.5760,\n          1.3174,  0.8276,  1.1031, -2.2923],\n        [ 2.0074, -0.9748,  4.2271, -1.3627,  2.1281,  5.0002,  2.8409,  4.8095,\n          4.1569, -2.1050,  2.1765,  0.1136],\n        [ 2.7924, -1.6973, -0.2003,  0.7660,  4.1585, -1.6020,  3.6093,  2.6253,\n         -3.2674,  4.3917,  2.5396,  4.9447]], dtype=torch.float64)\n\ntensor([[ 3.8656,  1.3284, -1.5308,  3.3376, -0.4621,  0.2892,  2.7335,  3.0972,\n         -0.1248,  2.8151,  5.8099,  3.6580],\n        [-0.5239,  3.0540,  2.8499,  5.5352, -1.2822, -0.5769,  0.1856,  1.4774,\n          0.1558, -3.8694,  3.1556,  1.1047],\n        [ 2.0523, -0.0245,  2.2404,  3.5180, -1.7726, -1.0308, -0.0828, -0.4857,\n          3.2845, -1.0730, -1.6905,  0.2296]], dtype=torch.float64)\ntensor([[ 2.8656,  1.3284, -0.5308,  5.3376,  2.5379,  4.2892,  7.7335,  9.0972,\n          6.8752, 10.8151, 14.8099, 13.6580],\n        [-1.5239,  3.0540,  3.8499,  7.5352,  1.7178,  3.4231,  5.1856,  7.4774,\n          7.1558,  4.1306, 12.1556, 11.1047],\n        [ 1.0523, -0.0245,  3.2404,  5.5180,  1.2274,  2.9692,  4.9172,  5.5143,\n         10.2845,  6.9270,  7.3095, 10.2296]], dtype=torch.float64)tensor([[ 1.4826,  5.1952,  4.7874,  1.0766,  5.4066,  2.3841,  5.8351,  6.5760,\n          8.3174,  8.8276, 10.1031,  7.7077],\n        [ 1.0074, -0.9748,  5.2271,  0.6373,  5.1281,  9.0002,  7.8409, 10.8095,\n         11.1569,  5.8950, 11.1765, 10.1136],\n        [ 1.7924, -1.6973,  0.7997,  2.7660,  7.1585,  2.3980,  8.6093,  8.6253,\n          3.7326, 12.3917, 11.5396, 14.9447]], dtype=torch.float64)tensor([[ 1.0671,  2.6969,  1.8514,  0.6595,  7.0573,  6.0755,  5.7563,  4.3395,\n          5.4599, 12.5793, 11.0644, 11.5522],\n        [ 2.0204,  4.0176, -1.1433,  4.3995, -0.1010,  5.6278,  6.9354,  6.2640,\n          9.9204,  9.8859,  9.8619, 14.2904],\n        [-0.0912,  1.8131, -0.4052,  3.0041,  0.3913,  5.1652,  7.0075,  8.3882,\n          3.5826, 11.6927, 13.0512, 10.6945]], dtype=torch.float64)tensor([[-0.6854,  5.3409, -0.3149,  5.3966,  6.5702,  3.9273,  6.6537,  7.9108,\n         10.0153,  4.6509,  9.7743, 13.3507],\n        [ 2.0062,  2.5177,  5.8994,  1.7826,  2.4013,  4.7463,  4.8404,  6.6335,\n          5.3505,  5.5296,  8.3507,  9.8919],\n        [-4.8354,  2.0587, -0.2134,  4.6090,  6.5504,  1.7156,  8.9482,  6.5007,\n          8.9596, 12.6309, 14.5908,  9.2887]], dtype=torch.float64)\n\n\n\ntensor([[ 1.4328],\n        [-0.7619],\n        [ 0.5262],\n        [ 0.5335],\n        [ 1.0102],\n        [-0.0456],\n        [-0.3427],\n        [ 1.0031],\n        [-2.4177],\n        [ 0.7413],\n        [ 0.5037],\n        [ 0.8962]], dtype=torch.float64)\nadding by 1st col of data 3 tensor([[ 2.2239,  4.9365,  3.5287, -1.1821,  2.1479, -1.8746,  0.5764,  0.3173,\n          1.0587,  0.5689,  0.8443, -2.5510],\n        [ 1.5110, -1.4711,  3.7307, -1.8591,  1.6318,  4.5039,  2.3445,  4.3132,\n          3.6606, -2.6013,  1.6801, -0.3827],\n        [ 2.6886, -1.8011, -0.3041,  0.6622,  4.0547, -1.7059,  3.5055,  2.5215,\n         -3.3712,  4.2879,  2.4358,  4.8409]], dtype=torch.float64)adding by 1st col of data 2 tensor([[-1.0282,  3.9982, -2.6576,  2.0538,  2.2275, -1.4154,  0.3110,  0.5680,\n          1.6725, -4.6919, -0.5684,  2.0080],\n        [ 3.0092,  2.5207,  4.9025, -0.2144, -0.5956,  0.7494, -0.1565,  0.6366,\n         -1.6465, -2.4673, -0.6463, -0.1050],\n        [-7.2531, -1.3590, -4.6311, -0.8087,  0.1327, -5.7021,  0.5305, -2.9170,\n         -1.4581,  1.2132,  2.1731, -4.1290]], dtype=torch.float64)adding by 1st col of data 0 tensor([[ 4.2984,  1.7612, -1.0981,  3.7704, -0.0293,  0.7220,  3.1663,  3.5300,\n          0.3080,  3.2479,  6.2427,  4.0908],\n        [-2.2858,  1.2920,  1.0880,  3.7732, -3.0442, -2.3388, -1.5763, -0.2845,\n         -1.6061, -5.6313,  1.3937, -0.6572],\n        [ 1.5785, -0.4984,  1.7666,  3.0442, -2.2465, -1.5046, -0.5567, -0.9596,\n          2.8107, -1.5469, -2.1644, -0.2442]], dtype=torch.float64)adding by 1st col of data 1 tensor([[ 1.6006,  2.2304,  0.3849, -1.8069,  3.5908,  1.6090,  0.2898, -2.1270,\n         -2.0066,  4.1129,  1.5979,  1.0857],\n        [ 3.0306,  4.0278, -2.1330,  2.4097, -3.0908,  1.6380,  1.9456,  0.2742,\n          2.9307,  1.8961,  0.8722,  4.3006],\n        [-0.1369,  0.7675, -2.4508, -0.0415, -3.6543,  0.1195,  0.9619,  1.3426,\n         -4.4631,  2.6470,  3.0056, -0.3511]], dtype=torch.float64)\n\n\n\nrslt, diagonal set to zero 3 tensor([[ 1.4826,  4.1952,  2.7874, -1.9234,  1.4066, -2.6159, -0.1649, -0.4240,\n          0.3174,  0.0000,  0.1031, -3.2923],\n        [ 1.0074, -1.9748,  3.2271, -2.3627,  1.1281,  4.0002,  1.8409,  3.8095,\n          3.1569, -3.1050,  0.0000, -0.8864],\n        [ 1.7924, -2.6973, -1.2003, -0.2340,  3.1585, -2.6020,  2.6093,  1.6253,\n         -4.2674,  3.3917,  1.5396,  0.0000]], dtype=torch.float64)rslt, diagonal set to zero 2 tensor([[-0.6854,  4.3409, -2.3149,  2.3966,  2.5702, -1.0727,  0.0000,  0.9108,\n          2.0153, -4.3491, -0.2257,  2.3507],\n        [ 2.0062,  1.5177,  3.8994, -1.2174, -1.5987, -0.2537, -1.1596,  0.0000,\n         -2.6495, -3.4704, -1.6493, -1.1081],\n        [-4.8354,  1.0587, -2.2134,  1.6090,  2.5504, -3.2844,  2.9482, -0.4993,\n","name":"stdout"},{"output_type":"stream","text":"          0.0000,  3.6309,  4.5908, -1.7113]], dtype=torch.float64)rslt, diagonal set to zero 0 tensor([[ 0.0000,  0.3284, -2.5308,  2.3376, -1.4621, -0.7108,  1.7335,  2.0972,\n         -1.1248,  1.8151,  4.8099,  2.6580],\n        [-1.5239,  0.0000,  1.8499,  4.5352, -2.2822, -1.5769, -0.8144,  0.4774,\n         -0.8442, -4.8694,  2.1556,  0.1047],\n        [ 1.0523, -1.0245,  0.0000,  2.5180, -2.7726, -2.0308, -1.0828, -1.4857,\n          2.2845, -2.0730, -2.6905, -0.7704]], dtype=torch.float64)\n\nrslt, diagonal set to zero 1 tensor([[ 1.0671e+00,  1.6969e+00, -1.4859e-01,  0.0000e+00,  3.0573e+00,\n          1.0755e+00, -2.4375e-01, -2.6605e+00, -2.5401e+00,  3.5793e+00,\n          1.0644e+00,  5.5216e-01],\n        [ 2.0204e+00,  3.0176e+00, -3.1433e+00,  1.3995e+00,  0.0000e+00,\n          6.2783e-01,  9.3536e-01, -7.3602e-01,  1.9204e+00,  8.8589e-01,\n         -1.3806e-01,  3.2904e+00],\n        [-9.1244e-02,  8.1309e-01, -2.4052e+00,  4.0822e-03, -3.6087e+00,\n          0.0000e+00,  1.0075e+00,  1.3882e+00, -4.4174e+00,  2.6927e+00,\n          3.0512e+00, -3.0545e-01]], dtype=torch.float64)\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Matrix multiplications"},{"metadata":{},"cell_type":"markdown","source":"Six different scenarios of matrix-matrix multiplications, each representing a different configuration of the split dimension of two input\nmatrices and the output matrix, were considered and implemented. \n\n< Content of Table 1 here >\n\n\n\nThe implementation of each case is carried\nout using the collective communication directives. Matrix multiplication scenarios are automatically selected based on the shapes of the input matrices A and\nB, except for the Scenarios 1 and 3 sharing the same input structure. Those two are further\ndistinguished by the shape of output, AB. The nonnegative matrix factorization involves Scenarios 1 to 5.\nScenario 6 is for matrix-vector multiplications, where broadcasting small vectors is almost\nalways efficient."},{"metadata":{"trusted":true},"cell_type":"code","source":"from dist_stat.distmm import *\ndef test_distmm(rank, size):\n    TType = torch.DoubleTensor\n    p = 12; q = 8; r = 2\n    if rank==0:\n        fat   = TType(p, q).normal_()\n        thin1 = TType(q, r).normal_()\n        thin2 = TType(p, r).normal_()\n\n    else:\n        fat, thin1, thin2 = None, TType(q,r), TType(p,r)\n    dist.broadcast(thin1,0)\n    dist.broadcast(thin2,0)\n\n    fat_dist   = distmat.dist_data(fat, src=0, TType=TType)\n    thin1_dist = distmat.dist_data(thin1, src=0, TType=TType)\n    thin2_dist = distmat.dist_data(thin2, src=0, TType=TType)\n\n    # test distmm_thinthin_inner \n    if rank==0: \n        print(\"distmm_thinthin_inner: thin1^T x thin1\")\n        thin1_thin1 = torch.mm(torch.t(thin1), thin1)\n        print(\"thin1^T x thin1: \", thin1_thin1)\n\n    thin1_thin1_bd = distmm_thinthin_inner(thin1_dist.t(), thin1_dist)\n    print(\"rslt in rank %d: \"%(rank,), thin1_thin1_bd)\n\n    dist.barrier()\n\n\n    if rank==0:\n        print(\"distmm_db_d: thin2 x thin1_thin1\")\n        correct = torch.mm(thin2, thin1_thin1)\n        print(correct)\n    rslt_dist = distmm_db_d(thin2_dist, thin1_thin1_bd)\n    print(\"rslt in rand %d: \"%(rank,), rslt_dist.chunk)\n    print(rslt_dist.byrow)\n\n\n    dist.barrier()\n\n    if rank==0:\n        print(\"distmm_db_d (reverse): thin1_thin1 x thin2^T\")\n        correct = torch.mm(thin1_thin1, torch.t(thin2))\n        print(correct)\n    rslt_dist = distmm_db_d(thin2_dist.t(), thin1_thin1_bd, True)\n    print(\"rslt in rand %d: \"%(rank,), rslt_dist.chunk)\n    print(rslt_dist.byrow)\n\n    dist.barrier()\n\n    if rank==0:\n        print(\"_distmm_fatthin_byrow: fat x thin1\")\n        correct = torch.mm(fat, thin1)\n        print(correct)\n    rslt_dist = distmm_fatthin(fat_dist, thin1_dist)\n    print(\"rslt in rand %d: \"%(rank,), rslt_dist.chunk)\n    print(rslt_dist.byrow)\n\n    dist.barrier()\n\n    if rank==0:\n        print(\"_distmm_fatthin_byrow (reverse): thin1^T x fat^T\")\n        correct = torch.mm(torch.t(thin1), torch.t(fat))\n        print(correct)\n    rslt_dist = distmm_fatthin(fat_dist.t(), thin1_dist.t(), reverse=True)\n    print(\"rslt in rand %d: \"%(rank,), rslt_dist.chunk)\n    print(rslt_dist.byrow)\n\n    dist.barrier()\n\n    if rank==0:\n        print(\"_distmm_thinfat_byrow: thin2^T x fat\" )\n        # Note: this is reverse for distmm_fatthin, non-reverse for inner ftn\n        correct = torch.mm(torch.t(thin2), fat)\n        print(correct)\n    rslt_dist = distmm_fatthin(fat_dist, thin2_dist.t(), reverse=True, \n                                out_sizes=thin1_dist.sizes)\n    print(\"rslt in rand %d: \"%(rank,), rslt_dist.chunk)\n    print(rslt_dist.byrow)\n\n    dist.barrier()\n\n    if rank==0:\n        print(\"_distmm_thinfat_byrow (reverse): fat^T x thin2\" )\n        # Note: this is reverse for distmm_fatthin, non-reverse for inner ftn\n        correct = torch.mm(torch.t(fat), thin2)\n        print(correct)\n    rslt_dist = distmm_fatthin(fat_dist.t(), thin2_dist, reverse=False, \n                                out_sizes=thin1_dist.sizes)\n    print(\"rslt in rand %d: \"%(rank,), rslt_dist.chunk)\n    print(rslt_dist.byrow)\n\n    if rank==0:\n        print(\"distmm_thinthin_outer: thin1 x thin2^T\" )\n        correct = torch.mm(thin1, torch.t(thin2))\n        print(correct)\n    rslt_dist = distmm_thinthin_outer(thin1_dist, thin2_dist.t())\n    print(\"rslt in rank %d: \"%(rank,), rslt_dist.chunk)\n    print(rslt_dist.byrow)\n\n    if rank==0:\n        print(\"distmm_db_b: thin1^T x thin1(dense)\" )\n        correct = torch.mm(torch.t(thin1), thin1)\n        print(correct)\n    rslt_dist = distmm_db_b(thin1_dist.t(), thin1)\n    print(\"rslt in rank %d: \"%(rank,), rslt_dist)\n\n\n    dist.barrier()\n    if rank==0:\n        print(\"now we check distributed sparse matrices.\")\n\n    def to_sparse(x):\n        \"\"\" converts dense tensor x to sparse format \"\"\"\n        x_typename = torch.typename(x).split('.')[-1]\n        sparse_tensortype = getattr(torch.sparse, x_typename)\n\n        indices = torch.nonzero(x)\n        if len(indices.shape) == 0:  # if all elements are zeros\n            return sparse_tensortype(*x.shape)\n        indices = indices.t()\n        values = x[tuple(indices[i] for i in range(indices.shape[0]))]\n        return sparse_tensortype(indices, values, x.size())\n    \n    thin1_sparse_chunk = to_sparse(thin1_dist.chunk)\n    thin1_sparse_dist = THDistMat.from_chunks(thin1_sparse_chunk)\n    thin2_sparse_chunk = to_sparse(thin2_dist.chunk)\n    thin2_sparse_dist = THDistMat.from_chunks(thin2_sparse_chunk)\n    print(thin1_sparse_chunk.shape)\n    print(thin1_sparse_dist.t().shape)\n    print(thin1_dist.shape)\n    if rank==0:\n        print(\"correct: \", torch.mm(thin1.t(), thin1))\n\n    r =  distmat.mm(thin1_sparse_dist.t(), thin1_dist )\n    print(\"rslt: \", r)\n    ","execution_count":85,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_process(4, test_distmm)","execution_count":86,"outputs":[{"output_type":"stream","text":"distmm_thinthin_inner: thin1^T x thin1\nthin1^T x thin1:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)\n","name":"stdout"},{"output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n/srv/conda/envs/notebook/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n/srv/conda/envs/notebook/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n/srv/conda/envs/notebook/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n","name":"stderr"},{"output_type":"stream","text":"rslt in rank 0:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)\nrslt in rank 1:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)rslt in rank 2:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)rslt in rank 3:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)\n\n\ndistmm_db_d: thin2 x thin1_thin1\ntensor([[ 20.4717, -20.9301],\n        [ -0.3866,  -2.3102],\n        [  3.4683,  -1.9985],\n        [ 10.0434, -21.7488],\n        [ -8.9008,   1.7786],\n        [ 14.3755, -13.4916],\n        [ 14.6289,   6.1289],\n        [-11.1466,  -3.2908],\n        [ -4.6314,  17.0375],\n        [ -4.6952,  -2.8811],\n        [ 27.1388,  -5.2625],\n        [ -7.5063,  -3.7725]], dtype=torch.float64)\nrslt in rand 3:  tensor([[-4.6952, -2.8811],\n        [27.1388, -5.2625],\n        [-7.5063, -3.7725]], dtype=torch.float64)rslt in rand 0:  tensor([[ 20.4717, -20.9301],\n        [ -0.3866,  -2.3102],\n        [  3.4683,  -1.9985]], dtype=torch.float64)\n\nrslt in rand 1:  tensor([[ 10.0434, -21.7488],\n        [ -8.9008,   1.7786],\n        [ 14.3755, -13.4916]], dtype=torch.float64)rslt in rand 2:  tensor([[ 14.6289,   6.1289],\n        [-11.1466,  -3.2908],\n        [ -4.6314,  17.0375]], dtype=torch.float64)\nTrue\nTrue\n\nTrue\nTrue\ndistmm_db_d (reverse): thin1_thin1 x thin2^T\ntensor([[ 20.4717,  -0.3866,   3.4683,  10.0434,  -8.9008,  14.3755,  14.6289,\n         -11.1466,  -4.6314,  -4.6952,  27.1388,  -7.5063],\n        [-20.9301,  -2.3102,  -1.9985, -21.7488,   1.7786, -13.4916,   6.1289,\n          -3.2908,  17.0375,  -2.8811,  -5.2625,  -3.7725]],\n       dtype=torch.float64)\nrslt in rand 0:  tensor([[ 20.4717,  -0.3866,   3.4683],\n        [-20.9301,  -2.3102,  -1.9985]], dtype=torch.float64)rslt in rand 1:  tensor([[ 10.0434,  -8.9008,  14.3755],\n        [-21.7488,   1.7786, -13.4916]], dtype=torch.float64)\nrslt in rand 3:  tensor([[-4.6952, 27.1388, -7.5063],\n        [-2.8811, -5.2625, -3.7725]], dtype=torch.float64)rslt in rand 2:  tensor([[ 14.6289, -11.1466,  -4.6314],\n        [  6.1289,  -3.2908,  17.0375]], dtype=torch.float64)\nFalse\n\n\nFalse\nFalse\nFalse\n_distmm_fatthin_byrow: fat x thin1\ntensor([[-2.5992,  2.4633],\n        [11.2190, -6.3513],\n        [-1.4552,  2.8982],\n        [-2.4909, -3.5356],\n        [-3.3804,  3.2883],\n        [-2.1293, -1.2122],\n        [-5.5143,  1.4986],\n        [-0.4519, -2.3879],\n        [ 8.8853, -3.7040],\n        [-1.0206,  6.2059],\n        [ 4.3791,  4.5227],\n        [-4.9386, -1.6446]], dtype=torch.float64)\nrslt in rand 1:  tensor([[-2.4909, -3.5356],\n        [-3.3804,  3.2883],\n        [-2.1293, -1.2122]], dtype=torch.float64)rslt in rand 2:  tensor([[-5.5143,  1.4986],\n        [-0.4519, -2.3879],\n        [ 8.8853, -3.7040]], dtype=torch.float64)rslt in rand 3:  tensor([[-1.0206,  6.2059],\n        [ 4.3791,  4.5227],\n        [-4.9386, -1.6446]], dtype=torch.float64)rslt in rand 0:  tensor([[-2.5992,  2.4633],\n        [11.2190, -6.3513],\n        [-1.4552,  2.8982]], dtype=torch.float64)\n\n\nTrue\nTrue\n\nTrue\nTrue\n_distmm_fatthin_byrow (reverse): thin1^T x fat^T\ntensor([[-2.5992, 11.2190, -1.4552, -2.4909, -3.3804, -2.1293, -5.5143, -0.4519,\n          8.8853, -1.0206,  4.3791, -4.9386],\n        [ 2.4633, -6.3513,  2.8982, -3.5356,  3.2883, -1.2122,  1.4986, -2.3879,\n         -3.7040,  6.2059,  4.5227, -1.6446]], dtype=torch.float64)\nrslt in rand 0:  tensor([[-2.5992, 11.2190, -1.4552],\n        [ 2.4633, -6.3513,  2.8982]], dtype=torch.float64)\nrslt in rand 2:  tensor([[-5.5143, -0.4519,  8.8853],\n        [ 1.4986, -2.3879, -3.7040]], dtype=torch.float64)rslt in rand 1:  tensor([[-2.4909, -3.3804, -2.1293],\n        [-3.5356,  3.2883, -1.2122]], dtype=torch.float64)False\nrslt in rand 3:  tensor([[-1.0206,  4.3791, -4.9386],\n        [ 6.2059,  4.5227, -1.6446]], dtype=torch.float64)\n\n\nFalse\nFalse\nFalse\n_distmm_thinfat_byrow: thin2^T x fat\ntensor([[ 3.2638, -2.0531, -1.4650,  1.3398, -2.1822,  2.2660,  5.9041,  0.0584],\n        [-5.1742,  0.1255,  0.3624, -2.2235,  0.0063,  3.7953,  3.0134, -1.3422]],\n       dtype=torch.float64)\nrslt in rand 1:  tensor([[ 0.6312, -0.4432],\n        [-0.8251, -0.9634]], dtype=torch.float64)rslt in rand 0:  tensor([[ 70.2478,  -2.0531],\n        [-44.7147,   0.1255]], dtype=torch.float64)rslt in rand 3:  tensor([[ 3.2755, -0.7753],\n        [ 0.7638, -0.0223]], dtype=torch.float64)rslt in rand 2:  tensor([[-2.4445,  0.2279],\n        [-4.8714,  1.9004]], dtype=torch.float64)\n\n\n\nFalse\nFalse\nFalse\nFalse\n_distmm_thinfat_byrow (reverse): fat^T x thin2\ntensor([[ 3.2638, -5.1742],\n        [-2.0531,  0.1255],\n        [-1.4650,  0.3624],\n        [ 1.3398, -2.2235],\n        [-2.1822,  0.0063],\n        [ 2.2660,  3.7953],\n        [ 5.9041,  3.0134],\n        [ 0.0584, -1.3422]], dtype=torch.float64)\nrslt in rand 2:  tensor([[-2.4445, -4.8714],\n        [ 0.2279,  1.9004]], dtype=torch.float64)rslt in rand 1:  tensor([[ 0.6312, -0.8251],\n        [-0.4432, -0.9634]], dtype=torch.float64)rslt in rand 0:  tensor([[ 70.2478, -44.7147],\n        [ -2.0531,   0.1255]], dtype=torch.float64)\nrslt in rand 3:  tensor([[ 3.2755,  0.7638],\n        [-0.7753, -0.0223]], dtype=torch.float64)True\n\n\n\nTrue\nTrue\nTrue\ndistmm_thinthin_outer: thin1 x thin2^T\ntensor([[-2.3927,  0.0871, -0.4293, -0.9960,  1.1537, -1.6988, -2.0365,  1.5303,\n          0.3507,  0.6678, -3.5203,  1.0547],\n        [-1.8305, -0.0793, -0.2450, -1.3813,  0.4877, -1.2347, -0.4204,  0.3784,\n          0.9320,  0.0965, -1.4802,  0.1893],\n        [ 3.0447,  0.2430,  0.3439,  2.7690, -0.5105,  2.0041, -0.1665, -0.0263,\n         -2.0554,  0.1550,  1.5387,  0.1552],\n        [ 1.3633, -0.0686,  0.2555,  0.4869, -0.7087,  0.9764,  1.3082, -0.9749,\n         -0.1135, -0.4344,  2.1634, -0.6812],\n        [-2.0370, -0.4245, -0.0803, -2.9638, -0.3671, -1.2241,  2.1522, -1.4039,\n          2.5659, -0.8472,  1.1468, -1.2117],\n        [ 2.7335, -0.0078,  0.4381,  1.5268, -1.0700,  1.9000,  1.6121, -1.2506,\n         -0.8175, -0.5026,  3.2598, -0.8170],\n        [-2.2222, -0.5058, -0.0631, -3.4148, -0.5163, -1.3163,  2.6815, -1.7639,\n          2.9938, -1.0457,  1.6067, -1.5030],\n        [ 2.2380,  0.0890,  0.3041,  1.6549, -0.6178,  1.5131,  0.5763, -0.5060,\n         -1.1032, -0.1406,  1.8760, -0.2653]], dtype=torch.float64)\nrslt in rank 2:  tensor([[-2.0370, -0.4245, -0.0803, -2.9638, -0.3671, -1.2241,  2.1522, -1.4039,\n          2.5659, -0.8472,  1.1468, -1.2117],\n        [ 2.7335, -0.0078,  0.4381,  1.5268, -1.0700,  1.9000,  1.6121, -1.2506,\n         -0.8175, -0.5026,  3.2598, -0.8170]], dtype=torch.float64)\nrslt in rank 3:  tensor([[-2.2222, -0.5058, -0.0631, -3.4148, -0.5163, -1.3163,  2.6815, -1.7639,\n          2.9938, -1.0457,  1.6067, -1.5030],\n        [ 2.2380,  0.0890,  0.3041,  1.6549, -0.6178,  1.5131,  0.5763, -0.5060,\n         -1.1032, -0.1406,  1.8760, -0.2653]], dtype=torch.float64)rslt in rank 0:  tensor([[-2.3927,  0.0871, -0.4293, -0.9960,  1.1537, -1.6988, -2.0365,  1.5303,\n          0.3507,  0.6678, -3.5203,  1.0547],\n        [-1.8305, -0.0793, -0.2450, -1.3813,  0.4877, -1.2347, -0.4204,  0.3784,\n          0.9320,  0.0965, -1.4802,  0.1893]], dtype=torch.float64)rslt in rank 1:  tensor([[ 3.0447,  0.2430,  0.3439,  2.7690, -0.5105,  2.0041, -0.1665, -0.0263,\n         -2.0554,  0.1550,  1.5387,  0.1552],\n        [ 1.3633, -0.0686,  0.2555,  0.4869, -0.7087,  0.9764,  1.3082, -0.9749,\n         -0.1135, -0.4344,  2.1634, -0.6812]], dtype=torch.float64)\nTrue\n\nTrue\n\nTrue\ndistmm_db_b: thin1^T x thin1(dense)\nTrue\ntensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)\nrslt in rank 0:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)\nrslt in rank 3:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)rslt in rank 2:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)rslt in rank 1:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)\n\n\nnow we check distributed sparse matrices.\ntorch.Size([2, 2])\ntorch.Size([2, 2])\ntorch.Size([2, 2])\ntorch.Size([2, 2])\n[2, 8]\n[2, 8]\n[2, 8]\n[2, 8]\n[8, 2]\n[8, 2]\n[8, 2]\ncorrect:  tensor([[18.8603, -5.5108],\n","name":"stdout"},{"output_type":"stream","text":"        [-5.5108, 13.0393]], dtype=torch.float64)[8, 2]\n\nrslt:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)rslt:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)rslt:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)\n\n\nrslt:  tensor([[18.8603, -5.5108],\n        [-5.5108, 13.0393]], dtype=torch.float64)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Nonnegative Matrix Factorization (NMF)"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"The following code is a simplified version. The full object-oriented version is available at the [GitHub repo](https://github.com/kose-y/dist_stat)."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def nmf(rank, size):\n    # TODO: initialization here\n    for i in range(maxiter):\n        XWt =  distmat.mm(data, W.t())\n        WWt =  distmat.mm(W, W.t())\n        VWWt = distmat.mm(V, WWt)\n        V.mul_(XWt).div_(VWWt)\n\n        VtX  = distmat.mm(V.t(), data, out_sizes=W.sizes)\n        VtV  = distmat.mm(V.t(), V)\n        VtVW = distmat.mm(VtV, W)\n        W = W.mul_(VtX).div_(VtVW)\n        if i % 10 == 0:\n            # print obj\n            pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## $\\ell_1$-regularized Cox Regression"},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def cox_l1(rank, size):\n    # TODO: initialization here\n    lambd = 0.01\n    soft_threshold = torch.nn.Softshrink(lambd)\n    for i in range(maxiter):\n        Xbeta = distmat.mm(data, beta)\n        w = Xbeta.exp()\n        W = w.cumsum(0)\n        w_dist = distmat.dist_data(w, TType=w.TType)\n        pi = (w_dist/W.t()) * pi_ind\n        pd  = distmat.mm(pi, delta)\n        dmpd = delta_dist - pd\n        grad = distmat.mm(datat, dmpd)\n        beta = (beta + grad * sigma).apply(soft_threshold)\n        if i % 10 == 0:\n            # print obj\n            pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multi-GPU Demonstration"},{"metadata":{},"cell_type":"markdown","source":"We demonstrate 10,000 x 10,000 examples on 2-8 GPUs on our server."},{"metadata":{},"cell_type":"markdown","source":"## Multi-node"},{"metadata":{},"cell_type":"markdown","source":"The data structure can also be utilized on multi-node clusters. The structure was used for the analysis of 200,000 x 500,000 UK Biobank data."},{"metadata":{},"cell_type":"markdown","source":"## Future Direction"},{"metadata":{},"cell_type":"markdown","source":"MPI-only, lightweight, more flexible version in Julia is in preparation. CUDA-aware MPI support for the central MPI interface [MPI.jl](https://github.com/JuliaParallel/MPI.jl) was added in the process."}],"metadata":{"kernelspec":{"name":"conda-env-notebook-py","display_name":"Python [conda env:notebook] *","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}
